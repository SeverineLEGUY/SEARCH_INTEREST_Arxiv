# ğŸš€ Data Pipeline avec Apache Airflow, FastAPI, Streamlit, MongoDB, PostgreSQL & MLflow

Ce projet met en place une architecture complÃ¨te de data pipeline basÃ©e sur Apache Airflow pour l'orchestration, FastAPI pour l'accÃ¨s aux donnÃ©es, Streamlit pour la visualisation, MongoDB et PostgreSQL pour le stockage, et MLflow pour le suivi des expÃ©riences de Machine Learning.

## ğŸ“¦ Services inclus

| Service               | Port    | Description |
|-----------------------|---------|-------------|
| Airflow Webserver     | `8080`  | Interface d'administration d'Airflow |
| Airflow Scheduler     | -       | Planification des DAGs |
| Airflow Worker        | -       | ExÃ©cution des tÃ¢ches avec Celery |
| Airflow Triggerer     | -       | Gestion des triggers (ex. capteurs) |
| PostgreSQL            | -       | Base de donnÃ©es utilisÃ©e par Airflow |
| Redis                 | `6379`  | Broker Celery pour Airflow |
| MongoDB               | `27017` | Base de donnÃ©es utilisÃ©e par l'API backend |
| FastAPI               | `8500`  | Backend API pour accÃ©der aux donnÃ©es |
| Streamlit             | `8501`  | Interface web de visualisation |
| MLflow                | `5050`  | Suivi des expÃ©rimentations ML |

---

## ğŸ—ï¸ Structure des dossiers

```bash
.
â”œâ”€â”€ airflow/              # Dossiers Airflow (DAGs, logs, plugins)
â”œâ”€â”€ backend/              # Code de l'API FastAPI
â”œâ”€â”€ frontend/             # Interface Streamlit
â”œâ”€â”€ mlruns/               # Dossiers de suivi MLflow
â”œâ”€â”€ .env                  # Fichier dâ€™environnement
â”œâ”€â”€ docker-compose.yaml   # Configuration Docker complÃ¨te
â”œâ”€â”€ import_env_to_airflow.py  # Script d'import des variables d'env dans Airflow

# ğŸš€ Data Pipeline avec Apache Airflow, FastAPI, Streamlit, MongoDB, PostgreSQL & MLflow

Ce projet met en place une **architecture complÃ¨te de MLOps** pour lâ€™automatisation du cycle de vie dâ€™un modÃ¨le de Machine Learning appliquÃ© aux articles scientifiques publiÃ©s sur lâ€™**API ArXiv en temps rÃ©el**.

ConcrÃ¨tement, le pipeline :

-  **RÃ©cupÃ¨re automatiquement** les nouveaux articles publiÃ©s sur lâ€™API ArXiv ;  
-  **Stocke et organise** les donnÃ©es brutes dans plusieurs bases :  
            - Redis pour le cache  
            - MongoDB pour le NoSQL  
            - PostgreSQL pour le relationnel  
- ğŸ·ï¸ **CatÃ©gorise** les articles selon leurs domaines scientifiques ;  
- ğŸ“ **GÃ©nÃ¨re un rÃ©sumÃ© et une traduction multilingue** grÃ¢ce Ã  un **LLM Mistral** ;  
- ğŸŒ **Expose les rÃ©sultats** via :  
            - une API REST (FastAPI)  
            - une interface utilisateur interactive (Streamlit)  
- ğŸ“Š **Suit et versionne les modÃ¨les** avec **MLflow** (traÃ§abilitÃ© des expÃ©riences, mÃ©triques, artefacts) ;  
- âš™ï¸ **Orchestre et automatise** toutes les Ã©tapes avec **Airflow** (extraction, transformation, stockage, entraÃ®nement, dÃ©ploiement) ;  
- ğŸš€ **DÃ©ploie la solution en continu** grÃ¢ce Ã  **Docker** + **Jenkins/GitHub Actions** (CI/CD) ;  
- ğŸ‘€ **Supervise le comportement en production** avec **Evidently** (suivi de la dÃ©rive de donnÃ©es et des performances).  


## ğŸ“¦ Services inclus

| Service               | Port    | Description |
|-----------------------|---------|-------------|
| Airflow Webserver     | `8082`  | Interface d'administration d'Airflow |
| Airflow Scheduler     | -       | Planification et orchestration des DAGs |
| Airflow Worker        | -       | ExÃ©cution des tÃ¢ches distribuÃ©es via Celery |
| Airflow Triggerer     | -       | Gestion des triggers et capteurs (sensors) |
| PostgreSQL            | `5432`  | Base de donnÃ©es relationnelle (Airflow + MLflow metadata) |
| Redis                 | `6379`  | Broker Celery pour la communication entre Scheduler et Workers |
| MongoDB               | `27017` | Base de donnÃ©es NoSQL utilisÃ©e par lâ€™API backend |
| FastAPI               | `8500`  | Backend API pour accÃ©der aux donnÃ©es traitÃ©es |
| Streamlit             | `8501`  | Interface web pour la visualisation et lâ€™interaction utilisateur |
| MLflow                | `5050`  | Suivi et versionnage des expÃ©riences ML (mÃ©triques, artefacts, modÃ¨les) |
| Jenkins               | `8080`  | Serveur CI/CD pour lâ€™intÃ©gration et le dÃ©ploiement continu |
| Evidently             | -       | Monitoring des modÃ¨les en production (dÃ©rive de donnÃ©es, qualitÃ©, mÃ©triques) |

---

## ğŸ—ï¸ Structure des dossiers

```bash
.
â”œâ”€â”€ airflow/                  # Dossiers Airflow (DAGs, logs, plugins)
â”œâ”€â”€ backend/                  # Code de l'API FastAPI
â”œâ”€â”€ frontend/                 # Interface Streamlit
â”œâ”€â”€ jenkins                   # Pipeline CI/CD 
â”œâ”€â”€ mlflow/                   # Dossiers de suivi MLflow
â”œâ”€â”€ .env                      # Fichier dâ€™environnement
â”œâ”€â”€ docker-compose.yaml       # Configuration Docker complÃ¨te
â”œâ”€â”€ import_env_to_airflow.py  # Script d'import des variables d'env dans Airflow

```

## ğŸš€ Initialisation et Lancement

### 1ï¸âƒ£ Cloner le dÃ©pÃ´t
```bash
git clone https://github.com/SeverineLEGUY/SEARCH_INTEREST_Arxiv.git
cd SEARCH_INTEREST_Arxiv
```

### 2ï¸âƒ£ Configurer les variables dâ€™environnement

CrÃ©er un fichier `.env` Ã  partir du template fourni :  
```bash
cp .env.template .env

# ARXIV
ARXIV_CATEGORY="cs.AI"
ARXIV_START_DATE="2025-01-01T00:00:00Z"

# Redis
REDIS_HOST="airflow-run-redis"
REDIS_PORT="6379"
REDIS_TRAINQ="arxiv_classifier_train_test"
REDIS_CLASSQ="arxiv_classifier"

# MongoDB
MONGO_URI="mongodb://backend-run-mongodb:27017/"
MONGO_DB="arxiv"
MONGO_SUMMARIZE="arxiv_summaries"
MONGO_CLASSIFY="arxiv_classifications"

# MLflow
MLFLOW_TRACKING_URI=http://mlflow:5050

# API Keys
MISTRAL_API_KEY=
AWS_ACCESS_KEY_ID=
AWS_SECRET_ACCESS_KEY=

```
### 3ï¸âƒ£ Construire et lancer les services
      ```bash
       docker compose up --build
       docker ps
  ```     
### 4ï¸âƒ£ AccÃ©der aux interfaces

* Airflow â†’ [http://localhost:8082](http://localhost:8082) â†—ï¸
* FastAPI â†’ [http://localhost:8500/docs](http://localhost:8500/docs) â†—ï¸
* Streamlit â†’ [http://localhost:8501](http://localhost:8501) â†—ï¸
* MLflow â†’ [http://localhost:5050](http://localhost:5050) â†—ï¸
* Jenkins â†’ [http://localhost:8080](http://localhost:8080) â†—ï¸



### ğŸ—‚ï¸ DAGs et ordre dâ€™exÃ©cution

Lancez manuellement les DAGs d'EntraÃ®nement 
   - 1. cleanup_redis_and_mongo â†’ Vide les bases Redis et MongoDB
   - 2. arxiv_to_redis_train â†’  RÃ©cupÃ¨re un Ã©chantillon dâ€™articles depuis lâ€™API ArXiv
   - 3. arxiv_training â†’ EntraÃ®ne le modÃ¨le de classification (LLM Mistral) et enregistre la version du modÃ¨le dans MLflow.  
Puis activez les trois DAGs de Production pour lancement auto selon la frequence indiquÃ©
   - 4. arxiv_to_redis (8 minutes)  â†’ recupÃ¨re les nouveaux articles Arxiv pour les mettre dans la queue redis
   - 5. summarize_arxiv_article (30 min) â†’ rÃ©sumÃ© automatique des articles Ã  lâ€™aide du LLM Mistral
   - 6. classify_arxiv_article (45 min) â†’ CatÃ©gorise les articles par domaine scientifique 
   - 7. evidently_daily_drift_monitoring : suivi quotidie de derive de donnÃ©es et de performance du modÃ¨le en production.  

âš ï¸ Remarque : lâ€™ordre doit Ãªtre respectÃ©. Les dÃ©pendances entre DAGs peuvent Ãªtre configurÃ©es dans Airflow.
# üöÄ Data Pipeline avec Apache Airflow, FastAPI, Streamlit, MongoDB, PostgreSQL & MLflow

Ce projet met en place une architecture compl√®te de data pipeline bas√©e sur Apache Airflow pour l'orchestration, FastAPI pour l'acc√®s aux donn√©es, Streamlit pour la visualisation, MongoDB et PostgreSQL pour le stockage, et MLflow pour le suivi des exp√©riences de Machine Learning.

## üì¶ Services inclus

| Service               | Port    | Description |
|-----------------------|---------|-------------|
| Airflow Webserver     | `8080`  | Interface d'administration d'Airflow |
| Airflow Scheduler     | -       | Planification des DAGs |
| Airflow Worker        | -       | Ex√©cution des t√¢ches avec Celery |
| Airflow Triggerer     | -       | Gestion des triggers (ex. capteurs) |
| PostgreSQL            | -       | Base de donn√©es utilis√©e par Airflow |
| PostgreSQL            | -       | Base de donn√©es utilis√©e par mlFlow |
| Redis                 | `6379`  | Broker Celery pour Airflow |
| MongoDB               | `27017` | Base de donn√©es utilis√©e par l'API backend |
| FastAPI               | `8500`  | Backend API pour acc√©der aux donn√©es |
| Streamlit             | `8501`  | Interface web de visualisation |
| MLflow                | `5050`  | Suivi des exp√©rimentations ML |

---

## üèóÔ∏è Structure des dossiers

```bash
.
‚îú‚îÄ‚îÄ airflow/              # Dossiers Airflow (DAGs, logs, plugins)
‚îú‚îÄ‚îÄ backend/              # Code de l'API FastAPI
‚îú‚îÄ‚îÄ frontend/             # Interface Streamlit
‚îú‚îÄ‚îÄ mlflow/               # Dossiers de suivi MLflow
‚îú‚îÄ‚îÄ .env                  # Fichier d‚Äôenvironnement
‚îú‚îÄ‚îÄ docker-compose.yaml   # Configuration Docker compl√®te
‚îú‚îÄ‚îÄ import_env_to_airflow.py  # Script d'import des variables d'env dans Airflow

Excellent ! Tous vos services critiques sont Up (y compris Airflow, MLflow, FastAPI et Streamlit), ce qui signifie que votre plateforme est enti√®rement fonctionnelle. L'anomalie (unhealthy) de MongoDB est mineure √† ce stade.

Ordre de Lancement des DAGs Airflow
Vous avez trois √©tapes principales pour mettre en service votre pipeline (Entra√Ænement, Classification, et Maintenance). L'ordre id√©al pour commencer et assurer que le mod√®le est pr√™t avant d'√™tre utilis√© est le suivant :

√âtape 1 : Entra√Ænement Initial du Mod√®le (Manuel)
C'est l'√©tape la plus importante √† lancer en premier pour que le mod√®le puisse √™tre utilis√© par la suite.

cleanup_redis_and_mongo (Optionnel, mais fortement recommand√©)

Action : Ex√©cutez ce DAG d'abord pour vider les files Redis et les collections MongoDB.

But : Assure un environnement de travail propre avant la collecte de nouvelles donn√©es.

arxiv_to_redis_train

Action : Lancez ce DAG apr√®s le nettoyage.

But : Il va chercher un grand volume d'articles ArXiv (via la date fixe 2024-01-01T00:00:00Z dans fetch_arxiv_train.py) et les pousser dans la file Redis d√©di√©e √† l'entra√Ænement (REDIS_TRAINQ).

arxiv_training

Action : Lancez ce DAG imm√©diatement apr√®s que le DAG arxiv_to_redis_train a termin√© sa collecte.

But : Il va consommer les articles dans la file Redis, entra√Æner le mod√®le de classification (Logistic Regression), et enregistrer le mod√®le, le LabelEncoder et les m√©triques dans MLflow.

√âtape 2 : D√©marrage de la Production (Automatique)
Une fois que le mod√®le est entra√Æn√© (√©tape 1), vous pouvez activer la classification et la publication.

Activation des DAGs de Production (Commutateur ON)

Vous avez trois DAGs qui sont configur√©s pour s'ex√©cuter automatiquement √† intervalles r√©guliers (schedule_interval est d√©fini dans le code, mais ils sont en pause √† la cr√©ation par d√©faut).

Action : Activez (mettez sur ON) les DAGs suivants dans l'interface Airflow (en cliquant sur le commutateur √† gauche de leur nom) :

arxiv_to_redis (Toutes les 8 minutes)

classify_arxiv_article (Toutes les 45 minutes)

summarize_arxiv_article (Toutes les 30 minutes)

But :

arxiv_to_redis va chercher les nouveaux articles ArXiv (via la date mise √† jour automatiquement) et les met dans la file Redis de classification (REDIS_CLASSQ).

summarize_arxiv_article va prendre les articles et ajouter un r√©sum√© fran√ßais (via l'API Mistral) dans MongoDB.

classify_arxiv_article va prendre les articles, les classifier avec le mod√®le MLflow, et ajouter le r√©sultat √† MongoDB.

R√©capitulatif de la Premi√®re Connexion
Ouvrez Airflow sur http://localhost:8082. (Identifiants par d√©faut sont souvent airflow/airflow ou admin/admin).

Lancez les DAGs d'Entra√Ænement (√âtape 1) dans l'ordre cleanup ‚Üí arxiv_to_redis_train ‚Üí arxiv_training.

Une fois l'entra√Ænement termin√©, activez les trois DAGs de Production (√âtape 2).

Vous pourrez ensuite consulter les r√©sultats :

Mod√®le entra√Æn√© : http://localhost:5050 (MLflow UI)

Donn√©es trait√©es : http://localhost:8501 (Streamlit UI)
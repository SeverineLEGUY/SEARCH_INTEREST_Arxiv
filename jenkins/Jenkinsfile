pipeline {
    agent any

    environment {
        TEST_IMAGE = 'arxive-tests'
        APP_IMAGE = 'arxiv-app'
        AWS_ACCESS_KEY_ID     = credentials('AWS_ACCESS_KEY_ID')
        AWS_SECRET_ACCESS_KEY = credentials('AWS_SECRET_ACCESS_KEY')
        AWS_DEFAULT_REGION    = 'eu-west-3'
        S3_BUCKET_NAME        = 'bucketarxiv'
    }

    stages {

        stage('Build Test Container') {
            steps {
                // MODIFICATION 1 : Changement du contexte de build
                // Exécuté à la racine du workspace (dir('.')) pour inclure TOUS les fichiers du projet
                dir('.') { 
                    // Utilise '.' (la racine du projet) comme contexte de build à la fin de la commande
                    sh "docker build -t ${TEST_IMAGE} -f jenkins/tests/Dockerfile_test ."
                }
            }
        }

        stage('Run Unit Tests') {
            steps {
                script {
                    // MODIFICATION 2 : Exécuté à la racine du workspace pour un chemin absolu
                    dir('.') {
                        sh """
                        docker run --rm \\
                            --env AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID} \\
                            --env AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY} \\
                            --env AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION} \\
                            ${TEST_IMAGE}
                        """
                    }
                }
            }
            post {
                always {
                    // Le rapport JUnit se trouve maintenant dans le chemin 'jenkins/tests' de l'image Docker,
                    // et doit être récupéré depuis la racine du workspace Jenkins.
                    junit 'jenkins/tests/junit-report.xml'
                }
            }
        }

        stage('Build ETL Container') {
            steps {
                dir('jenkins') {
                    // Construit le container principal pour le ETL
                    sh "docker build -t ${APP_IMAGE} ."
                }
            }
        }

        stage('Run ETL and Upload to S3') {
            steps {
                script {
                    dir('jenkins') {
                        echo "Starting ETL Process using image: ${APP_IMAGE}"
                        
                        // Exécuter le processus ETL
                        sh "docker run --rm -v ${WORKSPACE}/data:/app/data ${APP_IMAGE} python etl_process.py"
                        
                        echo "ETL finished. Uploading output_data.csv to S3..."
                        
                        // Upload vers S3
                        sh """
                        docker run --rm \\
                            --env AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID} \\
                            --env AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY} \\
                            --env AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION} \\
                            ${APP_IMAGE} python upload_s3.py ${S3_BUCKET_NAME} data/output_data.csv
                        """
                    }
                }
            }
        }
    }

    post {
        success {
            echo '✅ Pipeline completed successfully!'
        }
        failure {
            echo '❌ Pipeline failed.'
        }
    }
}